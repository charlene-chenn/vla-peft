{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.0080422216637346,
  "eval_steps": 500,
  "global_step": 1000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.040211108318673035,
      "grad_norm": 23.151397705078125,
      "learning_rate": 8.444444444444444e-05,
      "loss": 28.3679,
      "step": 20
    },
    {
      "epoch": 0.08042221663734607,
      "grad_norm": 2.402862310409546,
      "learning_rate": 0.00017333333333333334,
      "loss": 20.3015,
      "step": 40
    },
    {
      "epoch": 0.1206333249560191,
      "grad_norm": 1.6668062210083008,
      "learning_rate": 0.00019995393663024054,
      "loss": 17.7249,
      "step": 60
    },
    {
      "epoch": 0.16084443327469214,
      "grad_norm": 1.218038558959961,
      "learning_rate": 0.00019972842227844787,
      "loss": 17.0002,
      "step": 80
    },
    {
      "epoch": 0.20105554159336517,
      "grad_norm": 1.8855749368667603,
      "learning_rate": 0.00019931541975950378,
      "loss": 16.7749,
      "step": 100
    },
    {
      "epoch": 0.2412666499120382,
      "grad_norm": 0.6629523634910583,
      "learning_rate": 0.00019871570551289805,
      "loss": 16.7658,
      "step": 120
    },
    {
      "epoch": 0.28147775823071125,
      "grad_norm": 1.1657142639160156,
      "learning_rate": 0.00019793040699379682,
      "loss": 16.4277,
      "step": 140
    },
    {
      "epoch": 0.3216888665493843,
      "grad_norm": 0.9205684661865234,
      "learning_rate": 0.00019696100055344124,
      "loss": 16.683,
      "step": 160
    },
    {
      "epoch": 0.3618999748680573,
      "grad_norm": 0.9021503925323486,
      "learning_rate": 0.00019580930866362604,
      "loss": 16.6944,
      "step": 180
    },
    {
      "epoch": 0.40211108318673033,
      "grad_norm": 0.6708090305328369,
      "learning_rate": 0.00019447749649047542,
      "loss": 16.6862,
      "step": 200
    },
    {
      "epoch": 0.44232219150540336,
      "grad_norm": 1.2588716745376587,
      "learning_rate": 0.0001929680678239585,
      "loss": 16.6784,
      "step": 220
    },
    {
      "epoch": 0.4825332998240764,
      "grad_norm": 0.5250007510185242,
      "learning_rate": 0.00019128386037079587,
      "loss": 16.7838,
      "step": 240
    },
    {
      "epoch": 0.5227444081427495,
      "grad_norm": 1.1095997095108032,
      "learning_rate": 0.0001894280404196069,
      "loss": 16.6343,
      "step": 260
    },
    {
      "epoch": 0.5629555164614225,
      "grad_norm": 0.7451302409172058,
      "learning_rate": 0.00018740409688832764,
      "loss": 16.6883,
      "step": 280
    },
    {
      "epoch": 0.6031666247800955,
      "grad_norm": 1.2837142944335938,
      "learning_rate": 0.00018521583476508905,
      "loss": 16.783,
      "step": 300
    },
    {
      "epoch": 0.6433777330987686,
      "grad_norm": 0.9047398567199707,
      "learning_rate": 0.00018286736795488802,
      "loss": 16.5984,
      "step": 320
    },
    {
      "epoch": 0.6835888414174416,
      "grad_norm": 0.5036806464195251,
      "learning_rate": 0.00018036311154549784,
      "loss": 16.4152,
      "step": 340
    },
    {
      "epoch": 0.7237999497361146,
      "grad_norm": 0.737265944480896,
      "learning_rate": 0.0001777077735071596,
      "loss": 16.4556,
      "step": 360
    },
    {
      "epoch": 0.7640110580547876,
      "grad_norm": 0.46105828881263733,
      "learning_rate": 0.00017490634584165773,
      "loss": 16.5862,
      "step": 380
    },
    {
      "epoch": 0.8042221663734607,
      "grad_norm": 0.57232266664505,
      "learning_rate": 0.0001719640951974202,
      "loss": 16.4969,
      "step": 400
    },
    {
      "epoch": 0.8444332746921337,
      "grad_norm": 0.4672178030014038,
      "learning_rate": 0.0001688865529682862,
      "loss": 16.6426,
      "step": 420
    },
    {
      "epoch": 0.8846443830108067,
      "grad_norm": 0.5884015560150146,
      "learning_rate": 0.00016567950489455616,
      "loss": 16.3299,
      "step": 440
    },
    {
      "epoch": 0.9248554913294798,
      "grad_norm": 0.5508126020431519,
      "learning_rate": 0.00016234898018587337,
      "loss": 16.7245,
      "step": 460
    },
    {
      "epoch": 0.9650665996481528,
      "grad_norm": 0.6139123439788818,
      "learning_rate": 0.00015890124018638638,
      "loss": 16.693,
      "step": 480
    },
    {
      "epoch": 1.0040211108318673,
      "grad_norm": 0.5358321666717529,
      "learning_rate": 0.00015534276660350175,
      "loss": 16.7988,
      "step": 500
    },
    {
      "epoch": 1.0040211108318673,
      "eval_loss": 5.836112976074219,
      "eval_runtime": 338.1274,
      "eval_samples_per_second": 1.307,
      "eval_steps_per_second": 1.307,
      "step": 500
    },
    {
      "epoch": 1.0442322191505404,
      "grad_norm": 0.5700353980064392,
      "learning_rate": 0.00015168024932235617,
      "loss": 16.522,
      "step": 520
    },
    {
      "epoch": 1.0844433274692133,
      "grad_norm": 0.41215842962265015,
      "learning_rate": 0.0001479205738289176,
      "loss": 16.5678,
      "step": 540
    },
    {
      "epoch": 1.1246544357878865,
      "grad_norm": 0.5999572277069092,
      "learning_rate": 0.00014407080826535896,
      "loss": 16.7718,
      "step": 560
    },
    {
      "epoch": 1.1648655441065594,
      "grad_norm": 0.6179393529891968,
      "learning_rate": 0.00014013819014204075,
      "loss": 16.6655,
      "step": 580
    },
    {
      "epoch": 1.2050766524252325,
      "grad_norm": 0.4743661880493164,
      "learning_rate": 0.00013613011273108343,
      "loss": 16.6684,
      "step": 600
    },
    {
      "epoch": 1.2452877607439055,
      "grad_norm": 0.6220004558563232,
      "learning_rate": 0.00013205411116710972,
      "loss": 16.2796,
      "step": 620
    },
    {
      "epoch": 1.2854988690625786,
      "grad_norm": 0.8807128071784973,
      "learning_rate": 0.00012791784828128724,
      "loss": 16.6889,
      "step": 640
    },
    {
      "epoch": 1.3257099773812515,
      "grad_norm": 0.593662679195404,
      "learning_rate": 0.00012372910019530336,
      "loss": 16.4578,
      "step": 660
    },
    {
      "epoch": 1.3659210856999247,
      "grad_norm": 0.4562923312187195,
      "learning_rate": 0.00011949574170235494,
      "loss": 16.6155,
      "step": 680
    },
    {
      "epoch": 1.4061321940185976,
      "grad_norm": 0.43545615673065186,
      "learning_rate": 0.00011522573146263744,
      "loss": 16.7277,
      "step": 700
    },
    {
      "epoch": 1.4463433023372707,
      "grad_norm": 0.602835476398468,
      "learning_rate": 0.00011092709704116464,
      "loss": 16.5829,
      "step": 720
    },
    {
      "epoch": 1.4865544106559436,
      "grad_norm": 0.8626323938369751,
      "learning_rate": 0.0001066079198160484,
      "loss": 16.6615,
      "step": 740
    },
    {
      "epoch": 1.5267655189746168,
      "grad_norm": 0.5281296968460083,
      "learning_rate": 0.00010227631978561056,
      "loss": 16.4491,
      "step": 760
    },
    {
      "epoch": 1.5669766272932897,
      "grad_norm": 0.5917266011238098,
      "learning_rate": 9.794044030288922e-05,
      "loss": 16.7949,
      "step": 780
    },
    {
      "epoch": 1.6071877356119628,
      "grad_norm": 0.48835277557373047,
      "learning_rate": 9.360843276623825e-05,
      "loss": 16.8068,
      "step": 800
    },
    {
      "epoch": 1.647398843930636,
      "grad_norm": 0.4521337151527405,
      "learning_rate": 8.928844129480227e-05,
      "loss": 16.514,
      "step": 820
    },
    {
      "epoch": 1.6876099522493089,
      "grad_norm": 0.7073079347610474,
      "learning_rate": 8.498858741767579e-05,
      "loss": 16.7499,
      "step": 840
    },
    {
      "epoch": 1.7278210605679818,
      "grad_norm": 0.6192887425422668,
      "learning_rate": 8.071695480553187e-05,
      "loss": 16.6801,
      "step": 860
    },
    {
      "epoch": 1.768032168886655,
      "grad_norm": 0.7837578654289246,
      "learning_rate": 7.648157407342386e-05,
      "loss": 16.537,
      "step": 880
    },
    {
      "epoch": 1.808243277205328,
      "grad_norm": 1.021036148071289,
      "learning_rate": 7.229040768333115e-05,
      "loss": 16.5065,
      "step": 900
    },
    {
      "epoch": 1.848454385524001,
      "grad_norm": 0.3948032855987549,
      "learning_rate": 6.815133497483157e-05,
      "loss": 16.4385,
      "step": 920
    },
    {
      "epoch": 1.888665493842674,
      "grad_norm": 0.8966449499130249,
      "learning_rate": 6.407213735204343e-05,
      "loss": 16.4098,
      "step": 940
    },
    {
      "epoch": 1.928876602161347,
      "grad_norm": 0.9605405330657959,
      "learning_rate": 6.0060483654684354e-05,
      "loss": 16.2809,
      "step": 960
    },
    {
      "epoch": 1.9690877104800202,
      "grad_norm": 0.6774159669876099,
      "learning_rate": 5.6123915740750046e-05,
      "loss": 16.8374,
      "step": 980
    },
    {
      "epoch": 2.0080422216637346,
      "grad_norm": 0.5870643854141235,
      "learning_rate": 5.226983430791722e-05,
      "loss": 16.6512,
      "step": 1000
    },
    {
      "epoch": 2.0080422216637346,
      "eval_loss": 5.834661960601807,
      "eval_runtime": 337.9891,
      "eval_samples_per_second": 1.308,
      "eval_steps_per_second": 1.308,
      "step": 1000
    }
  ],
  "logging_steps": 20,
  "max_steps": 1494,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 7.375110871921459e+17,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
